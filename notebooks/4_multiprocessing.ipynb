{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import qutip as qt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will show how to do multiprocessing on a \"real life\" example using `qutip`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of spin bath on electron Ramsey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to simulate the Ramsey signal from an electron spin, where the precession frequency is slightly different for each experiment because of a nuclear spin bath. The nuclear spin bath varies slowly, which means that frequency is stable within a single experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loosly based on https://nbviewer.org/urls/qutip.org/qutip-tutorials/tutorials-v5/time-evolution/003_qubit-dynamics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we first want to have a function that can simulate the signal over time of a single experiment for a given detuning of the precession frequency compared to a rotation frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramsey(time_array_s, detuning_hz=0):\n",
    "    H = detuning_hz * 2 * np.pi * qt.sigmaz() / 2.0\n",
    "    initial_state = 1 / np.sqrt(2) * (qt.basis(2, 0) + qt.basis(2, 1))\n",
    "    result = qt.mesolve(H, initial_state, time_array_s, e_ops=[qt.sigmax()])\n",
    "    sigma_x_timetrace = result.expect[0]\n",
    "    return sigma_x_timetrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first test that our function works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array_s = np.linspace(0, 2e-6)\n",
    "sigma_x = ramsey(time_array_s, 1e6)\n",
    "plt.plot(time_array_s, sigma_x)\n",
    "plt.title(\"Signal of 1 MHz detuning electron spin\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(r\"$\\sigma_x$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our notebooks cleaner and our precious simulation function reusable we move the function into our own library: `src/simulation_tutorial/lib.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_tutorial import lib\n",
    "\n",
    "lib.ramsey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using apply_ufunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup the same analysis in `xarray` so that we can easily sweep variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_TO_S = 1e-6\n",
    "MHZ_TO_HZ = 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset()\n",
    "ds[\"time_us\"] = np.linspace(0, 2, 100)\n",
    "ds.time_us.attrs = {\"long_name\": \"Time\", \"units\": \"us\"}\n",
    "ds[\"time_s\"] = ds.time_us * US_TO_S\n",
    "ds[\"detuning_MHz\"] = 1\n",
    "ds.detuning_MHz.attrs = {\"long_name\": \"Detuning\", \"units\": \"MHz\"}\n",
    "ds[\"detuning_Hz\"] = ds.detuning_MHz * MHZ_TO_HZ\n",
    "ds[\"sigma_x\"] = xr.apply_ufunc(\n",
    "    ramsey,\n",
    "    ds.time_s,\n",
    "    ds.detuning_Hz,\n",
    "    input_core_dims=[[\"time_us\"], []],\n",
    "    output_core_dims=[[\"time_us\"]],\n",
    "    vectorize=True,\n",
    "    keep_attrs=True,\n",
    ")\n",
    "ds.sigma_x.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sigma_x.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would a fluctuation bath show up in a Ramsey measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAUSSIAN_FWHM_TO_SIGMA = 1 / (\n",
    "    2 * np.sqrt(2 * np.log(2))\n",
    ")  # https://en.wikipedia.org/wiki/Full_width_at_half_maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_size = 1000\n",
    "detuning_MHz_mean = 0\n",
    "detuning_MHz_FWHM = 0.5\n",
    "detuning_MHz_sigma = detuning_MHz_FWHM * GAUSSIAN_FWHM_TO_SIGMA\n",
    "ds = xr.Dataset()\n",
    "ds[\"time_us\"] = np.linspace(0, 2, 100)\n",
    "ds.time_us.attrs = {\"long_name\": \"Time\", \"units\": \"us\"}\n",
    "ds[\"time_s\"] = ds.time_us * US_TO_S\n",
    "ds[\"detuning_MHz\"] = xr.DataArray(\n",
    "    np.random.normal(detuning_MHz_mean, detuning_MHz_sigma, mc_size), dims=\"mc\"\n",
    ")\n",
    "ds.detuning_MHz.attrs = {\"long_name\": \"Detuning\", \"units\": \"MHz\"}\n",
    "ds[\"detuning_Hz\"] = ds.detuning_MHz * MHZ_TO_HZ\n",
    "ds[\"sigma_x\"] = xr.apply_ufunc(\n",
    "    ramsey,\n",
    "    ds.time_s,\n",
    "    ds.detuning_Hz,\n",
    "    input_core_dims=[[\"time_us\"], []],\n",
    "    output_core_dims=[[\"time_us\"]],\n",
    "    vectorize=True,\n",
    "    keep_attrs=True,\n",
    ")\n",
    "ds.sigma_x.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the result of the simulations by plotting the first 10 realizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sigma_x.isel(mc=slice(0, 10)).plot(hue=\"mc\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take the average over the 'mc' dimension to get the expectation value of $\\sigma_x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"sigma_x_mean\"] = ds.sigma_x.mean(\"mc\")\n",
    "ds.sigma_x_mean.attrs = {\"long_name\": r\"E($\\sigma_x$)\"}\n",
    "ds.sigma_x_mean.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets use multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed this up we can use multiprocessing. For this I wrote a wrapper around apply_ufunc, which has the same functionality but on top accepts an argument `multiprocessing=True`. This only works when `vectorize=True` as it distributes the separate function calls over all processors. Without vectorizing there is only a single function call and this is usually much faster anyway. If you need it anyway use `dask`, see later in this notebook.\n",
    "\n",
    "The number of function calls given to a processor at once can be set with the argument `chunksize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_tutorial import xarray_mods as xrmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_size = 1000\n",
    "detuning_MHz_mean = 0\n",
    "detuning_MHz_FWHM = 0.5\n",
    "detuning_MHz_sigma = detuning_MHz_FWHM * GAUSSIAN_FWHM_TO_SIGMA\n",
    "ds = xr.Dataset()\n",
    "ds[\"time_us\"] = np.linspace(0, 2, 100)\n",
    "ds.time_us.attrs = {\"long_name\": \"Time\", \"units\": \"us\"}\n",
    "ds[\"time_s\"] = ds.time_us * US_TO_S\n",
    "ds[\"detuning_Mhz\"] = xr.DataArray(\n",
    "    np.random.normal(detuning_MHz_mean, detuning_MHz_sigma, mc_size), dims=\"mc\"\n",
    ")\n",
    "ds.detuning_Mhz.attrs = {\"long_name\": \"Detuning\", \"units\": \"MHz\"}\n",
    "ds[\"detuning_hz\"] = ds.detuning_Mhz * MHZ_TO_HZ\n",
    "ds[\"sigma_x\"] = xrmod.apply_ufunc(\n",
    "    ramsey,\n",
    "    ds.time_s,\n",
    "    ds.detuning_hz,\n",
    "    input_core_dims=[[\"time_us\"], []],\n",
    "    output_core_dims=[[\"time_us\"]],\n",
    "    vectorize=True,\n",
    "    keep_attrs=True,\n",
    "    multiprocessing=True,\n",
    "    chunksize=50,\n",
    ")\n",
    "ds.sigma_x.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "ds[\"sigma_x_exp\"] = ds.sigma_x.mean(\"mc\")\n",
    "ds.sigma_x_exp.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now sweep the detuning FWHM as well to understand its effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_size = 1000\n",
    "detuning_MHz_mean = 0\n",
    "ds = xr.Dataset()\n",
    "ds[\"time_us\"] = np.linspace(0, 2, 100)\n",
    "ds.time_us.attrs = {\"long_name\": \"Time\", \"units\": \"us\"}\n",
    "ds[\"time_s\"] = ds.time_us * US_TO_S\n",
    "ds[\"detuning_MHz_FWHM\"] = np.arange(0.2, 0.71, 0.1)\n",
    "ds.detuning_MHz_FWHM.attrs = {\"long_name\": \"FWHM\", \"units\": \"MHz\"}\n",
    "ds[\"detuning_MHz_sigma\"] = ds.detuning_MHz_FWHM * GAUSSIAN_FWHM_TO_SIGMA\n",
    "ds[\"detuning_Mhz\"] = xr.apply_ufunc(\n",
    "    np.random.normal,\n",
    "    detuning_MHz_mean,\n",
    "    ds.detuning_MHz_sigma,\n",
    "    mc_size,\n",
    "    output_core_dims=[[\"mc\"]],\n",
    "    vectorize=True,\n",
    ")\n",
    "ds.detuning_Mhz.attrs = {\"long_name\": \"Detuning\", \"units\": \"MHz\"}\n",
    "ds[\"detuning_hz\"] = ds.detuning_Mhz * MHZ_TO_HZ\n",
    "ds[\"sigma_x\"] = xrmod.apply_ufunc(\n",
    "    ramsey,\n",
    "    ds.time_s,\n",
    "    ds.detuning_hz,\n",
    "    input_core_dims=[[\"time_us\"], []],\n",
    "    output_core_dims=[[\"time_us\"]],\n",
    "    vectorize=True,\n",
    "    keep_attrs=True,\n",
    "    multiprocessing=True,\n",
    "    chunksize=50,\n",
    ")\n",
    "ds.sigma_x.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "ds[\"sigma_x_exp\"] = ds.sigma_x.mean(\"mc\")\n",
    "ds.sigma_x_exp.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sigma_x_exp.plot(hue=\"detuning_MHz_FWHM\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For long simulations it is worth to save the results to disk. The big advantage of `xarray` is that saving to dist in HDF5 format is very easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(\"../data/ramsey.hdf5\", engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also opening it again and using it for plotting is easy. \n",
    "\n",
    "For long simulations it is good practice to save the results to disk after simulation and read them from disk before plotting. In this way you don't lose all computation if the kernel crashes during plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loaded = xr.load_dataset(\"../data/ramsey.hdf5\")\n",
    "ds_loaded.sigma_x_exp.plot(hue=\"detuning_MHz_FWHM\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing using dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray` offers also a native way of multiprocessing using `dask`. It works less intuitive then my wrapper and has a much larger overhead so usually is slower that my wrapper, but allows for much more complicated features such as, larger than memory arrays, lazy evaluation, multithreading and multiprocessing and distributed computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed this up we can use `dask` arrays which can do multiprocessing.\n",
    "For this we need to chuck the data in parts that we want to run at once, e.g.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.detuning_hz.chunk(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot call the `chunk` directly on a coordinate of a dataset. Therefore you first need to pass it to `xr.DataArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_mc_realizations = 1000\n",
    "detuning_MHz_mean = 0\n",
    "detuning_MHz_sigma = 0.5\n",
    "ds = xr.Dataset()\n",
    "ds[\"time_us\"] = np.linspace(0, 2, 100)\n",
    "ds.time_us.attrs = {\"long_name\": \"Time\", \"units\": \"us\"}\n",
    "ds[\"time_s\"] = ds.time_us * US_TO_S\n",
    "ds[\"sigma_MHz\"] = np.arange(0.2, 0.82, 0.1)\n",
    "ds.sigma_MHz.attrs = {\"long_name\": \"Sigma\", \"units\": \"MHz\"}\n",
    "ds[\"detuning_Mhz\"] = xr.apply_ufunc(\n",
    "    np.random.normal,\n",
    "    detuning_MHz_mean,\n",
    "    ds.sigma_MHz,\n",
    "    number_of_mc_realizations,\n",
    "    output_core_dims=[[\"mc\"]],\n",
    "    vectorize=True,\n",
    ")\n",
    "ds.detuning_Mhz.attrs = {\"long_name\": \"Detuning\", \"units\": \"MHz\"}\n",
    "ds[\"detuning_hz\"] = ds.detuning_Mhz * MHZ_TO_HZ\n",
    "ds[\"sigma_x\"] = xrmod.apply_ufunc(\n",
    "    ramsey,\n",
    "    ds.time_s,\n",
    "    xr.DataArray(ds.detuning_hz).chunk(50),\n",
    "    input_core_dims=[[\"time_us\"], []],\n",
    "    output_core_dims=[[\"time_us\"]],\n",
    "    vectorize=True,\n",
    "    keep_attrs=True,\n",
    "    dask=\"parallelized\",\n",
    ")\n",
    "ds.sigma_x.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "ds[\"sigma_x_exp\"] = ds.sigma_x.mean(\"mc\")\n",
    "ds.sigma_x_exp.attrs = {\"long_name\": r\"$\\sigma_x$\"}\n",
    "with ProgressBar():\n",
    "    ds = ds.compute(scheduler=\"processes\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is faster than running it on a single core, but not as fast as my wrapper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
